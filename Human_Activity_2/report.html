<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Giovanni Fossati" />


<title>Machine-Learning-based Assessment of The Quality of Weight-lifting Exercises</title>

<script src="report_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="report_files/bootstrap-3.3.1/css/cerulean.min.css" rel="stylesheet" />
<script src="report_files/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="report_files/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="report_files/bootstrap-3.3.1/shim/respond.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; }
code > span.dt { color: #204a87; }
code > span.dv { color: #0000cf; }
code > span.bn { color: #0000cf; }
code > span.fl { color: #0000cf; }
code > span.ch { color: #4e9a06; }
code > span.st { color: #4e9a06; }
code > span.co { color: #8f5902; font-style: italic; }
code > span.ot { color: #8f5902; }
code > span.al { color: #ef2929; }
code > span.fu { color: #000000; }
code > span.er { font-weight: bold; }
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="css/gf_small_touches.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Machine-Learning-based Assessment of The Quality of Weight-lifting Exercises</h1>
<h4 class="author"><em>Giovanni Fossati</em></h4>
</div>


<div id="preamble" class="section level2">
<h2>PREAMBLE</h2>
<p>Report for the first assignment of the <a href="https://www.coursera.org/course/predmachlearn"><em>Practical Machine Learning</em></a> course of the <em>Coursera/JHSPH Data Science Specialization</em>.</p>
<p>The source files are posted on <a href="https://github.com/pedrosan/DataScienceExamples/tree/master/Human_Activity_2">GitHub</a></p>
</div>
<div id="introduction" class="section level1">
<h1>INTRODUCTION</h1>
<p>The rapid diffusion of sensors able to record physical parameters associated with motion (<em>e.g.</em> accelerometers), in dedicated devices and more importantly in general consumer electronics available/used by a broader population has sparked a great interest in developing applications taking advantage of these motion-related data. One area of particular interest concerns fitness-related activities.</p>
<p>This report summarizes the results of the development, and testing, of a <em>Machine Learning</em> model able to recognize the <em>quality</em> of a simple weight lifting exercise, namely whether or not it was performed appropropriately (and hence safely and effectively).</p>
<p>We used the dataset put together by the <a href="http://groupware.les.inf.puc-rio.br/har">research group on Human Activity Recognition</a> at the PUC of Rio de Janeiro.</p>
<p><a name="SUMMARY"></a></p>
</div>
<div id="summary-of-results" class="section level1">
<h1>SUMMARY OF RESULTS</h1>
<p>We tested three types of ML algorithms, all <em>tree-based</em> methods: <em>CART</em> trees, <em>boosted</em> trees, and <em>random forest</em>.</p>
<p>The first two methods failed to yield high quality results. This may have been caused by less than ideal choice of parameters, although in most cases we run them with the default values from <code>caret</code>, which are expected to be reasonable for decent results.</p>
<p><strong>Random forest</strong> models produced high quality results, with accuracies exceeding 99%, both in the built-in <em>Out Of the Bag</em> resampling, and on our separate <em>testing</em> subset.</p>
<p>Beside its clearly better performance, the choice of a random forest as an ensemble method is supported by its ability to handle multi-class problems.</p>
<p>We ran <em>random forest</em> models with <strong>three different <em>internal</em> cross-validation</strong> setups (implemented through the <code>trainControl()</code> function of <code>caret</code>): * 4-fold Cross-Validation, * bootstrap, and * <em>Leave Group Out Cross Validation</em>.</p>
<p>As noted, the trained models achieved exceptional accuracy in the ability of predicting the <em>outcome</em> variable <code>classe</code>, not only when tested against the 20-entries project benchmark, but more importantly when tested against the portion (25%) of the full dataset that we set aside for __validation_.</p>
<p>The results of a <em>random forest</em> model are not easily interpretable, even in presence of physically/motion based predictors. Nevertheless, as illustrated in some example plots, the data contain fairly clear pattern and differences between categories of exercise quality, that can be related to the slight differences in the motion of the body and weight dumbbell, and that are apparently very well picked out by the algorithm.</p>
<div id="outline" class="section level2">
<h2>Outline</h2>
<ul>
<li><a href="#THE_DATA_SET&quot;">THE DATA SET</a>
<ul>
<li><a href="#sensor_data">The Sensor Data</a></li>
</ul></li>
<li><a href="#DATA_PREPARATION&quot;">DATA PREPARATION</a>
<ul>
<li><a href="#cleaning">Cleaning/Tidying</a>
<ul>
<li>Non-sensor variables</li>
<li>Individual measurements <em>vs</em> <em>summaries</em> : the <code>new_window</code> variable</li>
</ul></li>
</ul></li>
<li><a href="#EXPLORATORY_ANALYSIS">EXPLORATORY ANALYSIS</a>
<ul>
<li>Features plotted vs. sequence index, and color coded by <code>user_name</code> and <code>classe</code></li>
<li>Feature vs. Feature plots with separate panels by <code>classe</code></li>
<li><a href="#feature_selection">About Feature Selection</a>
<ul>
<li>Zero/low Variance Predictors</li>
<li><em>Collinearity</em> Between Predictors</li>
</ul></li>
</ul></li>
<li><a href="#DATA_SPLITTING&quot;">DATA SPLITTING: “NEW” <em>TRAINING</em> AND <em>TESTING</em> SUBSETS</a>
<ul>
<li>Feature selection on <em>training</em> / <em>testing</em> subsets</li>
</ul></li>
<li><a href="#MODELING&quot;">MODELING</a>
<ul>
<li><a href="#model-summary">General Summary</a></li>
<li><a href="#model-rf1"><em>Random Forest</em> case 1 : 4-fold <em>CV</em></a></li>
<li><a href="#model-rf1"><em>Random Forest</em> case 2 : bootstrap, 25 reps</a></li>
<li><a href="#model-rf1"><em>Random Forest</em> case 3 : LGOCV, 25 repeats, 75%/25% splits</a></li>
</ul></li>
<li><a href="#APPENDIX&quot;">APPENDIX</a></li>
</ul>
<hr class="thin_separator">
<p><a name="THE_DATA"></a></p>
</div>
</div>
<div id="the-data" class="section level1">
<h1>THE DATA</h1>
<p>The data for the project were made available from the Coursera ML course webpage. Two separate sets were posted:</p>
<ul>
<li><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">a <em>training</em> dataset</a>. This set comprises a little over 16,000 entries for 160 variables.</li>
<li><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">a <em>testing</em> dataset</a>, to be used as a final project benchmark, comprising 20 “anonymized” entries.</li>
</ul>
<p>Data files were downloaded and read-in from local copies:</p>
<pre class="sourceCode r"><code class="sourceCode r">full &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./data/pml-training.csv.gz&quot;</span>, <span class="dt">na.strings=</span><span class="kw">c</span>(<span class="st">&quot;#DIV/0!&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;NA&quot;</span>), <span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>)
full &lt;-<span class="st"> </span><span class="kw">add_new_variables</span>(full)
alt.full &lt;-<span class="st"> </span><span class="kw">tidy_df</span>(full)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">TEST &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./data/pml-testing.csv.gz&quot;</span>, <span class="dt">na.strings=</span><span class="kw">c</span>(<span class="st">&quot;#DIV/0!&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;NA&quot;</span>), <span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>)
alt.TEST &lt;-<span class="st"> </span><span class="kw">tidy_df</span>(TEST)</code></pre>
<p><a name="structure"></a></p>
<div id="structure" class="section level3">
<h3>Structure</h3>
<p>The dataset comprises <strong>162 variables</strong>:</p>
<ul>
<li>152 actual <em>predictors</em>, <em>i.e.</em> the sensor data.</li>
<li>1 is the quality <em>class</em> of the exercise (<code>classe</code>, taking values <em>A</em>, <em>B</em>, <em>C</em>, <em>D</em>, <em>E</em>).</li>
<li>7 are auxiliary variables:
<ul>
<li>the <em>user</em> name (<code>user_name</code>).</li>
<li>3 time stamp related variables: <code>raw_timestamp_part_1</code>, <code>raw_timestamp_part_2</code>, <code>cvtd_timestamp</code>.</li>
<li>2 <em>exercise window</em> markers/counters: <code>new_window</code>, <code>num_window</code>.</li>
</ul></li>
</ul>
<p><a name="sensor_data"></a></p>
</div>
<div id="the-sensor-data" class="section level2">
<h2>The Sensor Data</h2>
<p>As described in the paper by <a href="http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201">Velloso et al.</a>, four <em>inertial measurement units</em> (IMU) where setup, placed on <em>belt</em>, <em>arm</em>, <em>forearm</em>, <em>dumbbell</em>. Each sensor measured 3-axes acceleration, gyroscope and magnetometer data at high cadence (45 Hz). These data were processed to yield 13 timed variables for each sensor:</p>
<ul>
<li><em>total acceleration</em>.</li>
<li><em>roll</em>, <em>pitch</em>, <em>yaw</em> angles.</li>
<li><em>x</em>, <em>y</em>, <em>z</em> values for <em>gyroscope</em>, <em>acceleleration</em>, and <em>magnetometer</em>.</li>
</ul>
<p>For instance, for the <em>belt</em> sensor the <em>basic timed data</em> are: <code>total_accel_belt</code>, <code>roll_belt</code>, <code>pitch_belt</code>, <code>yaw_belt</code>, <code>gyros_belt_x</code>, <code>gyros_belt_y</code>, <code>gyros_belt_z</code>, <code>accel_belt_x</code>, <code>accel_belt_y</code>, <code>accel_belt_z</code>, <code>magnet_belt_x</code>, <code>magnet_belt_y</code>, <code>magnet_belt_z</code>.</p>
<p>The dataset therefore comprises <span class="math">\(4 \times 13 = 52\)</span> <em>basic timed data</em>.</p>
<p>In addition to these, several statistical summaries are computed and reported for each exercise <em>window</em>, for each sensor:</p>
<ul>
<li>For <code>total_accel</code>, its variance <code>var_accel</code>.</li>
<li>For each of the three angles: <code>avg</code>, <code>stddev</code>, <code>var</code>, <code>kurtosis</code>, <code>skewness</code>, <code>max</code>, <code>min</code>, <code>amplitude</code> (<span class="math">\(3 \times 8\)</span> variables).</li>
</ul>
<p>These <span class="math">\(1 + 24 = 25\)</span> statistical summaries for each sensor add another <span class="math">\(100\)</span> variables to the dataset for a total of <span class="math">\(152\)</span> variables.</p>
<p>It is worth emphasizing that the dataset presents <em>timed</em> and <em>summary</em> variables all together in one table. While this may be practically convenient, it makes this dataset <em>un-tidy</em> by combining variables of different nature. Fortunately the two types of variables can be easily separated on the basis of the value of the <code>new_window</code> auxiliary variable, which has value <code>no</code> for entries corresponding to timed data, and <code>yes</code> for their statistical summaries over each exercise window.</p>
<hr class="thin_separator">
<p><a name="DATA_PREPARATION"></a></p>
</div>
</div>
<div id="data-preparation" class="section level1">
<h1>DATA PREPARATION</h1>
<p><a name="cleaning"></a></p>
<div id="cleaningtidying" class="section level2">
<h2>Cleaning/Tidying</h2>
<div id="non-sensor-variables" class="section level3">
<h3>Non-sensor variables</h3>
<p>Some variables should be discarded because associated with very specific aspects of the experiment that should be irrelevant from the point of view of its goal, such as <em>window</em> flags and <em>time stamps</em>.<br />These are the excluded variables: <code>X</code>, <code>user_name</code>, <code>new_window</code>, <code>num_window</code>, <code>cvtd_timestamp</code>, <code>raw_timestamp_part_1</code>, <code>raw_timestamp_part_2</code>.</p>
<p>Beside their intrinsic irrelevance, keeping these in would likely strongly drive the results in a completely spurious and meaningless way, because for instance the algorithm may hook on the <code>user_name</code> or <code>num_window</code>.</p>
</div>
<div id="individual-measurements-vs-summaries-the-new_window-variable" class="section level3">
<h3>Individual measurements <em>vs</em> <em>summaries</em> : the <code>new_window</code> variable</h3>
<p>To the best of my understanding, the dataset combines two different kinds of <em>observations</em>:</p>
<ul>
<li>single measurements of the main observables from the sensors, with some time cadence, and organized in <em>windows</em>, which are numbered (<code>num_window</code> variable).<br />These data have <code>new_window == &quot;no&quot;</code>.</li>
<li>statistical summaries of the measurements of each main observable over each <em>window</em>.<br />These data have <code>new_window == &quot;yes&quot;</code>, and</li>
</ul>
<p>We restricted our analysis to the 52 variables representing individual <em>timed</em> measurements, discarding the <em>summary</em> data.</p>
<pre class="sourceCode r"><code class="sourceCode r">alt.full &lt;-<span class="st"> </span><span class="kw">subset</span>(alt.full, new_window ==<span class="st"> &quot;no&quot;</span>)
alt.full.good &lt;-<span class="st"> </span><span class="kw">select_proper_vars</span>(alt.full)
alt.TEST.good &lt;-<span class="st"> </span><span class="kw">select_proper_vars</span>(alt.TEST)
alt.user &lt;-<span class="st"> </span>alt.full$user_name</code></pre>
<p>We also filtered out variables with <code>NA</code>, which basically means filtering against the <em>summary</em> variables.</p>
<pre class="sourceCode r"><code class="sourceCode r">alt.tt &lt;-<span class="st"> </span><span class="kw">colSums</span>(<span class="kw">is.na</span>(alt.full.good)) ==<span class="st"> </span><span class="dv">0</span>

alt.full.select &lt;-<span class="st"> </span>alt.full.good[, alt.tt]
alt.TEST.select &lt;-<span class="st"> </span>alt.TEST.good[, alt.tt]</code></pre>
<hr class="thin_separator">
<p><a name="EXPLORATORY_ANALYSIS"></a></p>
</div>
</div>
</div>
<div id="exploratory-analysis" class="section level1">
<h1>EXPLORATORY ANALYSIS</h1>
<div id="features-plotted-vs.sequence-index-and-color-coded-by-user_name-and-classe" class="section level2">
<h2>Features plotted vs. sequence index, and color coded by <code>user_name</code> and <code>classe</code></h2>
<p>These kind of plots shows that some of the features seem to correlated very strongly with the <em>user</em>, even more than with their <code>classe</code>, somewhat oddly.</p>
<p>This suggest that the training to predict the quality parameter of the weight lifting exercise (<code>classe</code>) that we can achieve with this dataset may not be easily generalized.</p>
<p><img src="figures/plots-examine2b-1.png" title="" alt="" width="600" style="display: block; margin: auto;" /></p>
<p><img src="figures/plots-examine2c-1.png" title="" alt="" width="600" style="display: block; margin: auto;" /></p>
</div>
<div id="feature-vs.feature-plots-with-separate-panels-by-classe" class="section level2">
<h2>Feature vs. Feature Plots with Separate Panels by <code>classe</code></h2>
<p>This second set of example plots shows that there are indeed some reasonably recognizable patterns allowing to distinguish between different <code>classe</code> categories.</p>
<p>The expectation is that the ML algorithm will be able to identify them and build on them a classification scheme.</p>
<p><img src="figures/plots-more_1-1.png" title="" alt="" width="600" style="display: block; margin: auto;" /></p>
<p><img src="figures/plots-more_2-1.png" title="" alt="" width="600" style="display: block; margin: auto;" /></p>
<p><a name="feature_selection"></a></p>
</div>
<div id="about-feature-selection" class="section level2">
<h2>About Feature Selection</h2>
<div id="zerolow-variance-predictors" class="section level3">
<h3>Zero/low Variance Predictors</h3>
<p>We checked the dataset for <em>un-informative</em> predictors, namely variables taking (nearly) unique values or having very little variance in their values.<br />The <code>caret</code> package provides a very convenient function to perform this quality-check, <code>nearZeroVar()</code>.</p>
<p>None of the 52 features meets the criteria for exclusion on the basis of <em>near Zero Variance</em>.<br />The full results of running it on our dataset (<code>nearZeroVar(alt.full.select, saveMetrics=TRUE)</code>) are reported in the <strong>Appendix</strong>.</p>
</div>
<div id="collinearity-between-predictors" class="section level3">
<h3><em>Collinearity</em> between predictors</h3>
<p>The presence of correlated predictor is undesirable because it can bias/mislead the modeling and in any case it may lead to run a model with an unnecessarily large(r) number of predictors. Although some ML algorithms are not negatively affected, it is generally safe to exclude correlated pr edictors.</p>
<p>For <em>tree-based</em> models it is actually recommended to clean the data set of correlated predictors because they end up sharing their overall <em>importance</em>, thus appearing to be less significant than they actually are.</p>
<p>We took advantage of the <code>caret</code> function <code>findCorrelation()</code> to identify variables whose absolute correlation value exceeds a set threshold (we chose 0.75) and obtain a list of variables to exclude selected among those with high correlation.</p>
<p>The actual predictors filtering was done applying this method just on the <em>training</em> subset (see below).</p>
<hr class="thin_separator">
<p><a name="DATA_SPLITTING"></a></p>
</div>
</div>
</div>
<div id="data-splitting-new-training-and-testing-subsets" class="section level1">
<h1>DATA SPLITTING: “NEW” <em>TRAINING</em> AND <em>TESTING</em> SUBSETS</h1>
<p>For validation purposes we split the full dataset in two subsets:</p>
<ul>
<li>a <em>training</em> subset, comprising 75% of the data.</li>
<li>a <em>testing</em> subset, comprising 25% of the data.</li>
</ul>
<p><strong>This <em>training</em> / <em>testing</em> split should not be confused with the original two datasets</strong>, which unfortunately are named also <em>training</em> and <em>testing</em>.</p>
<p>We are splitting the original <em>training</em> large dataset in two to be able to have an independent validation of the models, beyond what may already be done internally by some ML algorithms or by <code>caret</code> wrapped around them (<em>e.g.</em> by bootstrapping, or the built-in randomization and subsetting of <em>random forest</em> methods).</p>
<pre class="sourceCode r"><code class="sourceCode r">seed.split &lt;-<span class="st"> </span><span class="dv">12468</span>
<span class="kw">set.seed</span>(seed.split)
i.train.alt &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> alt.full.select$classe, <span class="dt">p=</span><span class="fl">0.75</span>, <span class="dt">list=</span><span class="ot">FALSE</span>)

alt.training &lt;-<span class="st"> </span>alt.full.select[i.train.alt, ]
alt.testing &lt;-<span class="st"> </span>alt.full.select[-i.train.alt, ]</code></pre>
<div id="feature-selection-on-training-testing-subsets" class="section level3">
<h3>Feature selection on <em>training</em> / <em>testing</em> subsets</h3>
<p>In the spirit of truly preserving the independence of the <em>testing</em> data subset, we performed the correlation-based feature reduction on the basis of the correlation between variables computed on the <em>training</em> subset instead of the full dataset, and applied the same variables filtering to the <em>testing</em> subset.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># correlation filtering done on the training subset</span>
alt.allCorr &lt;-<span class="st"> </span><span class="kw">cor</span>(alt.training[, -<span class="dv">1</span>])
i.fC<span class="fl">.75</span>.alt &lt;-<span class="st"> </span><span class="kw">findCorrelation</span>(alt.allCorr, <span class="dt">cutoff=</span><span class="fl">0.75</span>)</code></pre>
<p>The following plot shows the correlation matrix, with variables ordered on the basis of their <em>clustering</em>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">corrplot</span>(alt.allCorr, <span class="dt">order=</span><span class="st">&quot;hclust&quot;</span>, <span class="dt">method=</span><span class="st">&quot;color&quot;</span>, 
         <span class="dt">col=</span><span class="kw">color1</span>(<span class="dv">20</span>), <span class="dt">cl.length=</span><span class="dv">21</span>, <span class="dt">tl.cex=</span><span class="fl">0.8</span>, <span class="dt">tl.col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>))</code></pre>
<p><img src="figures/split_data-3-1.png" title="" alt="" width="800" style="display: block; margin: auto;" /></p>
<p>On the basis of their correlation, with a threshold of 0.75, these are the variables that would be excluded.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># variables to be excluded</span>
<span class="kw">colnames</span>(alt.training)[i.fC<span class="fl">.75</span>.alt<span class="dv">+1</span>]
<span class="co">#  [1] &quot;accel_belt_z&quot;      &quot;roll_belt&quot;         &quot;accel_belt_y&quot;      &quot;total_accel_belt&quot; </span>
<span class="co">#  [5] &quot;accel_dumbbell_z&quot;  &quot;accel_belt_x&quot;      &quot;pitch_belt&quot;        &quot;magnet_dumbbell_x&quot;</span>
<span class="co">#  [9] &quot;accel_dumbbell_y&quot;  &quot;magnet_dumbbell_y&quot; &quot;accel_dumbbell_x&quot;  &quot;accel_arm_x&quot;      </span>
<span class="co"># [13] &quot;accel_arm_z&quot;       &quot;magnet_arm_y&quot;      &quot;magnet_belt_y&quot;     &quot;accel_forearm_y&quot;  </span>
<span class="co"># [17] &quot;gyros_arm_y&quot;       &quot;gyros_forearm_z&quot;   &quot;gyros_forearm_y&quot;   &quot;gyros_dumbbell_x&quot;</span>

<span class="co"># variables selection</span>
alt.training.cut75 &lt;-<span class="st"> </span>alt.training[, -(i.fC<span class="fl">.75</span>.alt<span class="dv">+1</span>)]
alt.testing.cut75 &lt;-<span class="st"> </span>alt.testing[, -(i.fC<span class="fl">.75</span>.alt<span class="dv">+1</span>)]</code></pre>
<hr class="thin_separator">
<p><a name="MODELING"></a></p>
</div>
</div>
<div id="modeling" class="section level1">
<h1>MODELING</h1>
<p><a name="model-summary"></a></p>
<div id="general-summary" class="section level2">
<h2>General Summary</h2>
<p>We tested three types of ML algorithms, all within the framework provided by <code>caret</code>, and all generally speaking <em>tree-based</em> models.</p>
<ul>
<li>CART trees, namely <code>rpart2</code>.</li>
<li><em>boosted</em> tree, namely <code>gbm</code>.</li>
<li><em>random forest</em>, namely <code>rf</code>.</li>
</ul>
<p>The first two methods failed to yield high quality results, in fact in some cases their performance on the <em>testing</em> subset was very poor.<br />This may have been caused by less than ideal choice of parameters, but in most cases we let the modeling run with the default values from <code>caret</code>, which are expected to be reasonable for decent results.<br />We have to acknowledge that in some cases, in particular for the <code>gbm</code> models, the running time turned out to be very long and the memory requirements large enough to make it impractical, and we did not pursue those models more extensively.</p>
<p>On the other hand <strong>random forest</strong> models produced high quality results, with accuracies exceeding 99%, both in the built-in <em>Out Of the Bag</em> resampling, and on our separate <em>testing</em> subset.</p>
<p>In the next three sections we illustrate the results of <strong>random forest</strong> models run with <strong>three different <em>internal</em> cross-validation</strong> setups, implemented through the <code>trainControl()</code> function of <code>caret</code>:</p>
<ul>
<li><code>cv</code>: Cross-Validation, 4-fold (<em>i.e.</em> 75%/25% splits).</li>
<li><code>boot</code> (the default): bootstrap, 25 repeats.</li>
<li>’LGOCV`: Leave Group Out Cross Validation, 25 repeats, 75%/25% train/test splits of the data.</li>
</ul>
<p>In all cases we also tried a set of values for <code>mtry</code>, which regulates how many predictors are selected in the <em>random forest</em> random subsetting of variables.</p>
<hr class="thin_separator">
<p><a name="model-rf1"></a></p>
</div>
<div id="random-forest-case-1-4-fold-cv" class="section level2">
<h2><em>Random Forest</em> case 1 : 4-fold <em>CV</em></h2>
<p>With <code>mtry = 2, 6, 10, 18, 26, 34</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mtry.values &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">26</span>, <span class="dv">34</span>)

ctrl.rf1c &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number=</span><span class="dv">4</span>)

seed.rf1c &lt;-<span class="st"> </span><span class="dv">16790</span>; <span class="kw">set.seed</span>(seed.rf1c)
mod.alt.rf1c &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> alt.training.cut75[, -<span class="dv">1</span>], 
                      <span class="dt">y =</span> alt.training.cut75$classe, 
                      <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, 
                      <span class="dt">trControl =</span> ctrl.rf1c,
                      <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">mtry =</span> mtry.values),
                      <span class="dt">importance =</span> <span class="ot">TRUE</span>, 
                      <span class="dt">proximity =</span> <span class="ot">TRUE</span>)</code></pre>
<div id="fit-summary" class="section level3">
<h3>Fit Summary</h3>
<pre class="sourceCode r"><code class="sourceCode r">mod.alt.rf1c
<span class="co"># Random Forest </span>
<span class="co"># </span>
<span class="co"># 14414 samples</span>
<span class="co">#    32 predictor</span>
<span class="co">#     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; </span>
<span class="co"># </span>
<span class="co"># No pre-processing</span>
<span class="co"># Resampling: Cross-Validated (4 fold) </span>
<span class="co"># </span>
<span class="co"># Summary of sample sizes: 10811, 10810, 10811, 10810 </span>
<span class="co"># </span>
<span class="co"># Resampling results across tuning parameters:</span>
<span class="co"># </span>
<span class="co">#   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   </span>
<span class="co">#    2    0.9898018  0.9870959  0.003951942  0.005002063</span>
<span class="co">#    6    0.9911893  0.9888523  0.002982777  0.003774821</span>
<span class="co">#   10    0.9901487  0.9875353  0.003060048  0.003872692</span>
<span class="co">#   18    0.9879979  0.9848141  0.002999668  0.003797201</span>
<span class="co">#   26    0.9830026  0.9784937  0.003199211  0.004049294</span>
<span class="co">#   34    0.9777993  0.9719118  0.003413927  0.004319903</span>
<span class="co"># </span>
<span class="co"># Accuracy was used to select the optimal model using  the largest value.</span>
<span class="co"># The final value used for the model was mtry = 6.</span>

mod.alt.rf1c$finalModel
<span class="co"># </span>
<span class="co"># Call:</span>
<span class="co">#  randomForest(x = x, y = y, mtry = param$mtry, importance = TRUE) </span>
<span class="co">#                Type of random forest: classification</span>
<span class="co">#                      Number of trees: 500</span>
<span class="co"># No. of variables tried at each split: 6</span>
<span class="co"># </span>
<span class="co">#         OOB estimate of  error rate: 0.61%</span>
<span class="co"># Confusion matrix:</span>
<span class="co">#      A    B    C    D    E  class.error</span>
<span class="co"># A 4100    2    0    1    1 0.0009746589</span>
<span class="co"># B   17 2762   10    0    0 0.0096808892</span>
<span class="co"># C    0   19 2484   10    1 0.0119331742</span>
<span class="co"># D    1    0   21 2337    2 0.0101651842</span>
<span class="co"># E    0    0    1    2 2643 0.0011337868</span>

mod.alt.rf1c$results
<span class="co">#   mtry  Accuracy     Kappa  AccuracySD     KappaSD</span>
<span class="co"># 1    2 0.9898018 0.9870959 0.003951942 0.005002063</span>
<span class="co"># 2    6 0.9911893 0.9888523 0.002982777 0.003774821</span>
<span class="co"># 3   10 0.9901487 0.9875353 0.003060048 0.003872692</span>
<span class="co"># 4   18 0.9879979 0.9848141 0.002999668 0.003797201</span>
<span class="co"># 5   26 0.9830026 0.9784937 0.003199211 0.004049294</span>
<span class="co"># 6   34 0.9777993 0.9719118 0.003413927 0.004319903</span></code></pre>
</div>
<div id="predictions-on-testing-subset" class="section level3">
<h3>Predictions on <em>testing</em> subset</h3>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1c.test75 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1c, alt.testing.cut75, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="kw">confusionMatrix</span>(alt.testing.cut75$classe, pred.rf1c.test75)
<span class="co"># Confusion Matrix and Statistics</span>
<span class="co"># </span>
<span class="co">#           Reference</span>
<span class="co"># Prediction    A    B    C    D    E</span>
<span class="co">#          A 1364    3    0    0    0</span>
<span class="co">#          B    0  919    7    0    3</span>
<span class="co">#          C    0    6  824    8    0</span>
<span class="co">#          D    0    0   12  772    2</span>
<span class="co">#          E    0    0    0    1  881</span>
<span class="co"># </span>
<span class="co"># Overall Statistics</span>
<span class="co">#                                           </span>
<span class="co">#                Accuracy : 0.9913          </span>
<span class="co">#                  95% CI : (0.9882, 0.9937)</span>
<span class="co">#     No Information Rate : 0.284           </span>
<span class="co">#     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </span>
<span class="co">#                                           </span>
<span class="co">#                   Kappa : 0.9889          </span>
<span class="co">#  Mcnemar&#39;s Test P-Value : NA              </span>
<span class="co"># </span>
<span class="co"># Statistics by Class:</span>
<span class="co"># </span>
<span class="co">#                      Class: A Class: B Class: C Class: D Class: E</span>
<span class="co"># Sensitivity            1.0000   0.9903   0.9775   0.9885   0.9944</span>
<span class="co"># Specificity            0.9991   0.9974   0.9965   0.9965   0.9997</span>
<span class="co"># Pos Pred Value         0.9978   0.9892   0.9833   0.9822   0.9989</span>
<span class="co"># Neg Pred Value         1.0000   0.9977   0.9952   0.9978   0.9987</span>
<span class="co"># Prevalence             0.2840   0.1933   0.1756   0.1626   0.1845</span>
<span class="co"># Detection Rate         0.2840   0.1914   0.1716   0.1608   0.1835</span>
<span class="co"># Detection Prevalence   0.2847   0.1935   0.1745   0.1637   0.1837</span>
<span class="co"># Balanced Accuracy      0.9996   0.9939   0.9870   0.9925   0.9971</span></code></pre>
</div>
<div id="predictions-on-test-subset-the-20-benchmark-values-for-the-project" class="section level3">
<h3>Predictions on <em>TEST</em> subset (the 20 benchmark values for the Project)</h3>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1c.TEST &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1c, alt.TEST.select, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># comparison with &quot;truth&quot;</span>
pred.rf1c.TEST ==<span class="st"> </span>answers
<span class="co">#  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</span>
<span class="co"># [20] TRUE</span></code></pre>
</div>
<div id="variable-importance" class="section level3">
<h3>Variable Importance</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">varImp</span>(mod.alt.rf1c, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>)
<span class="co"># rf variable importance</span>
<span class="co"># </span>
<span class="co">#   variables are sorted by maximum importance across the classes</span>
<span class="co">#   only 20 most important variables shown (out of 32)</span>
<span class="co"># </span>
<span class="co">#                          A     B     C     D     E</span>
<span class="co"># yaw_belt             71.79 61.70 57.89 69.75 48.77</span>
<span class="co"># magnet_dumbbell_z    62.44 51.77 64.25 48.18 52.06</span>
<span class="co"># roll_dumbbell        36.91 46.06 61.96 48.89 43.28</span>
<span class="co"># magnet_belt_z        41.24 48.77 45.69 58.38 54.41</span>
<span class="co"># pitch_forearm        40.67 44.10 46.50 45.32 45.93</span>
<span class="co"># gyros_belt_z         35.62 43.83 37.73 44.62 46.31</span>
<span class="co"># roll_arm             28.81 44.13 37.71 46.26 33.29</span>
<span class="co"># roll_forearm         34.88 33.01 43.97 31.74 31.56</span>
<span class="co"># yaw_dumbbell         28.42 37.38 42.15 36.77 40.56</span>
<span class="co"># gyros_dumbbell_y     28.61 32.51 40.28 33.23 27.26</span>
<span class="co"># total_accel_dumbbell 31.76 35.98 34.25 33.40 39.88</span>
<span class="co"># magnet_forearm_z     32.86 38.47 31.33 37.96 35.49</span>
<span class="co"># yaw_arm              33.32 38.15 32.36 36.99 31.97</span>
<span class="co"># gyros_arm_x          20.95 36.79 29.31 34.78 29.26</span>
<span class="co"># magnet_belt_x        23.13 36.25 36.77 29.33 36.31</span>
<span class="co"># accel_forearm_x      21.83 31.82 32.37 36.20 29.57</span>
<span class="co"># pitch_arm            24.37 35.54 28.17 30.00 24.60</span>
<span class="co"># accel_forearm_z      22.17 29.58 34.86 29.02 30.99</span>
<span class="co"># magnet_arm_z         28.60 33.79 29.99 31.12 28.58</span>
<span class="co"># accel_arm_y          23.60 32.74 29.25 29.51 27.12</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot(varImp(mod.alt.rf1c, useModel=TRUE, scale=FALSE), top=ncol(mod.alt.rf1c$trainingData)-1)</span>
<span class="kw">dotPlot</span>(<span class="kw">varImp</span>(mod.alt.rf1c, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>), <span class="dt">top=</span><span class="kw">ncol</span>(mod.alt.rf1c$trainingData)-<span class="dv">1</span>)</code></pre>
<p><img src="figures/rf1c_post-plots-1.png" title="" alt="" width="700" style="display: block; margin: auto;" /></p>
<p><a name="model-rf2"></a></p>
</div>
</div>
<div id="random-forest-case-2-bootstrap-25-reps" class="section level2">
<h2><em>Random Forest</em> case 2 : bootstrap, 25 reps</h2>
<p>With <code>mtry = 2, 6, 10, 18, 26, 34</code></p>
<pre class="sourceCode r"><code class="sourceCode r">mtry.values &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">26</span>, <span class="dv">34</span>)

seed.rf1b &lt;-<span class="st"> </span><span class="dv">16789</span>; <span class="kw">set.seed</span>(seed.rf1b)
mod.rf1b &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> training.cut75[, -<span class="dv">1</span>], 
                      <span class="dt">y =</span> training.cut75$classe, 
                      <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, 
                      <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">mtry =</span> mtry.values))</code></pre>
<div id="fit-summary-1" class="section level3">
<h3>Fit Summary</h3>
<pre class="sourceCode r"><code class="sourceCode r">mod.rf1b
<span class="co"># Random Forest </span>
<span class="co"># </span>
<span class="co"># 14718 samples</span>
<span class="co">#    34 predictor</span>
<span class="co">#     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; </span>
<span class="co"># </span>
<span class="co"># No pre-processing</span>
<span class="co"># Resampling: Bootstrapped (25 reps) </span>
<span class="co"># </span>
<span class="co"># Summary of sample sizes: 14718, 14718, 14718, 14718, 14718, 14718, ... </span>
<span class="co"># </span>
<span class="co"># Resampling results across tuning parameters:</span>
<span class="co"># </span>
<span class="co">#   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   </span>
<span class="co">#    2    0.9880161  0.9848382  0.002011458  0.002541064</span>
<span class="co">#    6    0.9892243  0.9863680  0.001674175  0.002113586</span>
<span class="co">#   10    0.9887082  0.9857150  0.001479500  0.001868168</span>
<span class="co">#   18    0.9866414  0.9831000  0.001855994  0.002343789</span>
<span class="co">#   26    0.9835928  0.9792425  0.002145057  0.002708918</span>
<span class="co">#   34    0.9768211  0.9706757  0.002932730  0.003698371</span>
<span class="co"># </span>
<span class="co"># Accuracy was used to select the optimal model using  the largest value.</span>
<span class="co"># The final value used for the model was mtry = 6.</span>

mod.rf1b$finalModel
<span class="co"># </span>
<span class="co"># Call:</span>
<span class="co">#  randomForest(x = x, y = y, mtry = param$mtry) </span>
<span class="co">#                Type of random forest: classification</span>
<span class="co">#                      Number of trees: 500</span>
<span class="co"># No. of variables tried at each split: 6</span>
<span class="co"># </span>
<span class="co">#         OOB estimate of  error rate: 0.64%</span>
<span class="co"># Confusion matrix:</span>
<span class="co">#      A    B    C    D    E  class.error</span>
<span class="co"># A 4182    3    0    0    0 0.0007168459</span>
<span class="co"># B   13 2826    8    0    1 0.0077247191</span>
<span class="co"># C    0   19 2530   17    1 0.0144137125</span>
<span class="co"># D    0    0   21 2387    4 0.0103648425</span>
<span class="co"># E    0    0    2    5 2699 0.0025868441</span>

mod.rf1b$results
<span class="co">#   mtry  Accuracy     Kappa  AccuracySD     KappaSD</span>
<span class="co"># 1    2 0.9880161 0.9848382 0.002011458 0.002541064</span>
<span class="co"># 2    6 0.9892243 0.9863680 0.001674175 0.002113586</span>
<span class="co"># 3   10 0.9887082 0.9857150 0.001479500 0.001868168</span>
<span class="co"># 4   18 0.9866414 0.9831000 0.001855994 0.002343789</span>
<span class="co"># 5   26 0.9835928 0.9792425 0.002145057 0.002708918</span>
<span class="co"># 6   34 0.9768211 0.9706757 0.002932730 0.003698371</span></code></pre>
</div>
<div id="predictions-on-testing-subset-1" class="section level3">
<h3>Predictions on <em>testing</em> subset</h3>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1b.test75 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rf1b, testing.cut75, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="kw">confusionMatrix</span>(testing.cut75$classe, pred.rf1b.test75)
<span class="co"># Confusion Matrix and Statistics</span>
<span class="co"># </span>
<span class="co">#           Reference</span>
<span class="co"># Prediction    A    B    C    D    E</span>
<span class="co">#          A 1393    1    0    0    1</span>
<span class="co">#          B    7  936    4    0    2</span>
<span class="co">#          C    0    5  845    4    1</span>
<span class="co">#          D    0    0    5  799    0</span>
<span class="co">#          E    0    0    0    3  898</span>
<span class="co"># </span>
<span class="co"># Overall Statistics</span>
<span class="co">#                                           </span>
<span class="co">#                Accuracy : 0.9933          </span>
<span class="co">#                  95% CI : (0.9906, 0.9954)</span>
<span class="co">#     No Information Rate : 0.2855          </span>
<span class="co">#     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </span>
<span class="co">#                                           </span>
<span class="co">#                   Kappa : 0.9915          </span>
<span class="co">#  Mcnemar&#39;s Test P-Value : NA              </span>
<span class="co"># </span>
<span class="co"># Statistics by Class:</span>
<span class="co"># </span>
<span class="co">#                      Class: A Class: B Class: C Class: D Class: E</span>
<span class="co"># Sensitivity            0.9950   0.9936   0.9895   0.9913   0.9956</span>
<span class="co"># Specificity            0.9994   0.9967   0.9975   0.9988   0.9993</span>
<span class="co"># Pos Pred Value         0.9986   0.9863   0.9883   0.9938   0.9967</span>
<span class="co"># Neg Pred Value         0.9980   0.9985   0.9978   0.9983   0.9990</span>
<span class="co"># Prevalence             0.2855   0.1921   0.1741   0.1644   0.1839</span>
<span class="co"># Detection Rate         0.2841   0.1909   0.1723   0.1629   0.1831</span>
<span class="co"># Detection Prevalence   0.2845   0.1935   0.1743   0.1639   0.1837</span>
<span class="co"># Balanced Accuracy      0.9972   0.9952   0.9935   0.9950   0.9974</span></code></pre>
</div>
<div id="predictions-on-test-subset-the-20-benchmark-values-for-the-project-1" class="section level3">
<h3>Predictions on <em>TEST</em> subset (the 20 benchmark values for the Project)</h3>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1b.TEST &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rf1b, TEST.select, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># comparison with &quot;truth&quot;</span>
pred.rf1b.TEST ==<span class="st"> </span>answers
<span class="co">#  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</span>
<span class="co"># [20] TRUE</span></code></pre>
</div>
<div id="variable-importance-1" class="section level3">
<h3>Variable Importance</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">varImp</span>(mod.rf1b, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>)
<span class="co"># rf variable importance</span>
<span class="co"># </span>
<span class="co">#   only 20 most important variables shown (out of 34)</span>
<span class="co"># </span>
<span class="co">#                      Overall</span>
<span class="co"># yaw_belt              1155.1</span>
<span class="co"># magnet_dumbbell_z      806.5</span>
<span class="co"># pitch_forearm          762.5</span>
<span class="co"># magnet_belt_z          698.2</span>
<span class="co"># roll_forearm           625.6</span>
<span class="co"># roll_dumbbell          573.8</span>
<span class="co"># gyros_belt_z           498.8</span>
<span class="co"># roll_arm               414.8</span>
<span class="co"># total_accel_dumbbell   391.4</span>
<span class="co"># gyros_dumbbell_y       377.9</span>
<span class="co"># yaw_dumbbell           377.1</span>
<span class="co"># magnet_forearm_z       342.3</span>
<span class="co"># accel_forearm_x        333.3</span>
<span class="co"># magnet_arm_x           327.5</span>
<span class="co"># accel_forearm_z        320.5</span>
<span class="co"># pitch_dumbbell         306.6</span>
<span class="co"># magnet_belt_x          306.5</span>
<span class="co"># yaw_arm                284.8</span>
<span class="co"># magnet_forearm_y       271.6</span>
<span class="co"># magnet_forearm_x       235.4</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot(varImp(mod.rf1b, useModel=TRUE, scale=FALSE), top=ncol(mod.rf1b$trainingData)-1)</span>
<span class="kw">dotPlot</span>(<span class="kw">varImp</span>(mod.rf1b, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>), <span class="dt">top=</span><span class="kw">ncol</span>(mod.rf1b$trainingData)-<span class="dv">1</span>)</code></pre>
<p><img src="figures/rf1b_post-plots-1.png" title="" alt="" width="700" style="display: block; margin: auto;" /></p>
<p><a name="model-rf3"></a></p>
</div>
</div>
<div id="random-forest-case-3-lgocv-25-repeats-7525-splits" class="section level2">
<h2><em>Random Forest</em> case 3 : LGOCV, 25 repeats, 75%/25% splits</h2>
<p>With <code>mtry = 2, 4, 6, 8, 10</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mtryValues &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>)

ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;LGOCV&quot;</span>,
                     <span class="dt">classProbs =</span> <span class="ot">TRUE</span>)

seed.rf1e &lt;-<span class="st"> </span><span class="dv">17891</span>; <span class="kw">set.seed</span>(seed.rf1e)
mod.alt.rf1e &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> alt.training.cut75[, -<span class="dv">1</span>], 
                  <span class="dt">y =</span> alt.training.cut75$classe, 
                  <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, 
                  <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">mtry=</span>mtryValues),
                  <span class="dt">trControl =</span> ctrl,
                  <span class="dt">importance =</span> <span class="ot">TRUE</span>, 
                  <span class="dt">proximity =</span> <span class="ot">TRUE</span>)</code></pre>
<div id="fit-summary-2" class="section level3">
<h3>Fit Summary</h3>
<pre class="sourceCode r"><code class="sourceCode r">mod.alt.rf1e
<span class="co"># Random Forest </span>
<span class="co"># </span>
<span class="co"># 14414 samples</span>
<span class="co">#    32 predictor</span>
<span class="co">#     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; </span>
<span class="co"># </span>
<span class="co"># No pre-processing</span>
<span class="co"># Resampling: Repeated Train/Test Splits Estimated (25 reps, 0.75%) </span>
<span class="co"># </span>
<span class="co"># Summary of sample sizes: 10812, 10812, 10812, 10812, 10812, 10812, ... </span>
<span class="co"># </span>
<span class="co"># Resampling results across tuning parameters:</span>
<span class="co"># </span>
<span class="co">#   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   </span>
<span class="co">#    2    0.9896724  0.9869327  0.001744837  0.002208660</span>
<span class="co">#    4    0.9910383  0.9886615  0.001203534  0.001523144</span>
<span class="co">#    6    0.9910272  0.9886476  0.001361771  0.001723509</span>
<span class="co">#    8    0.9907052  0.9882400  0.001660179  0.002101095</span>
<span class="co">#   10    0.9903054  0.9877342  0.001701827  0.002153699</span>
<span class="co"># </span>
<span class="co"># Accuracy was used to select the optimal model using  the largest value.</span>
<span class="co"># The final value used for the model was mtry = 4.</span>

mod.alt.rf1e$finalModel
<span class="co"># </span>
<span class="co"># Call:</span>
<span class="co">#  randomForest(x = x, y = y, mtry = param$mtry, importance = TRUE) </span>
<span class="co">#                Type of random forest: classification</span>
<span class="co">#                      Number of trees: 500</span>
<span class="co"># No. of variables tried at each split: 4</span>
<span class="co"># </span>
<span class="co">#         OOB estimate of  error rate: 0.65%</span>
<span class="co"># Confusion matrix:</span>
<span class="co">#      A    B    C    D    E  class.error</span>
<span class="co"># A 4101    1    0    1    1 0.0007309942</span>
<span class="co"># B   18 2764    7    0    0 0.0089637863</span>
<span class="co"># C    0   19 2483   12    0 0.0123309467</span>
<span class="co"># D    0    0   28 2330    3 0.0131300296</span>
<span class="co"># E    0    0    1    3 2642 0.0015117158</span>

mod.alt.rf1e$results
<span class="co">#   mtry  Accuracy     Kappa  AccuracySD     KappaSD</span>
<span class="co"># 1    2 0.9896724 0.9869327 0.001744837 0.002208660</span>
<span class="co"># 2    4 0.9910383 0.9886615 0.001203534 0.001523144</span>
<span class="co"># 3    6 0.9910272 0.9886476 0.001361771 0.001723509</span>
<span class="co"># 4    8 0.9907052 0.9882400 0.001660179 0.002101095</span>
<span class="co"># 5   10 0.9903054 0.9877342 0.001701827 0.002153699</span></code></pre>
</div>
<div id="predictions-on-testing-subset-2" class="section level3">
<h3>Predictions on <em>testing</em> subset</h3>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1e.test75 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1e, alt.testing.cut75, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="kw">confusionMatrix</span>(alt.testing.cut75$classe, pred.rf1e.test75)
<span class="co"># Confusion Matrix and Statistics</span>
<span class="co"># </span>
<span class="co">#           Reference</span>
<span class="co"># Prediction    A    B    C    D    E</span>
<span class="co">#          A 1365    2    0    0    0</span>
<span class="co">#          B    0  920    6    0    3</span>
<span class="co">#          C    0    8  823    7    0</span>
<span class="co">#          D    0    0   12  771    3</span>
<span class="co">#          E    0    0    0    1  881</span>
<span class="co"># </span>
<span class="co"># Overall Statistics</span>
<span class="co">#                                           </span>
<span class="co">#                Accuracy : 0.9913          </span>
<span class="co">#                  95% CI : (0.9882, 0.9937)</span>
<span class="co">#     No Information Rate : 0.2843          </span>
<span class="co">#     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </span>
<span class="co">#                                           </span>
<span class="co">#                   Kappa : 0.9889          </span>
<span class="co">#  Mcnemar&#39;s Test P-Value : NA              </span>
<span class="co"># </span>
<span class="co"># Statistics by Class:</span>
<span class="co"># </span>
<span class="co">#                      Class: A Class: B Class: C Class: D Class: E</span>
<span class="co"># Sensitivity            1.0000   0.9892   0.9786   0.9897   0.9932</span>
<span class="co"># Specificity            0.9994   0.9977   0.9962   0.9963   0.9997</span>
<span class="co"># Pos Pred Value         0.9985   0.9903   0.9821   0.9809   0.9989</span>
<span class="co"># Neg Pred Value         1.0000   0.9974   0.9955   0.9980   0.9985</span>
<span class="co"># Prevalence             0.2843   0.1937   0.1751   0.1622   0.1847</span>
<span class="co"># Detection Rate         0.2843   0.1916   0.1714   0.1606   0.1835</span>
<span class="co"># Detection Prevalence   0.2847   0.1935   0.1745   0.1637   0.1837</span>
<span class="co"># Balanced Accuracy      0.9997   0.9935   0.9874   0.9930   0.9965</span></code></pre>
</div>
<div id="predictions-on-test-subset-the-20-benchmark-values-for-the-project-2" class="section level3">
<h3>Predictions on <em>TEST</em> subset (the 20 benchmark values for the Project)</h3>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1e.TEST &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1e, alt.TEST.select, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># comparison with &quot;truth&quot;</span>
pred.rf1e.TEST ==<span class="st"> </span>answers
<span class="co">#  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</span>
<span class="co"># [20] TRUE</span></code></pre>
</div>
<div id="variable-importance-2" class="section level3">
<h3>Variable Importance</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot(varImp(mod.alt.rf1e, useModel=TRUE, scale=FALSE), top=ncol(mod.alt.rf1e$trainingData)-1)</span>
<span class="kw">dotPlot</span>(<span class="kw">varImp</span>(mod.alt.rf1e, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>), <span class="dt">top=</span><span class="kw">ncol</span>(mod.alt.rf1e$trainingData)-<span class="dv">1</span>)</code></pre>
<p><img src="figures/rf1e_post-plots-1.png" title="" alt="" width="700" style="display: block; margin: auto;" /></p>
<hr class="separator">
<p><a name="APPENDIX"></a></p>
</div>
</div>
</div>
<div id="appendix" class="section level1">
<h1>APPENDIX</h1>
<div id="timed-vs.-summary-data-entries" class="section level3">
<h3><em>Timed</em> vs. <em>summary</em> data entries</h3>
<pre class="sourceCode r"><code class="sourceCode r">alt.statsNA &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">t</span>(<span class="kw">sapply</span>(alt.full.good, function(x){ <span class="kw">c</span>(<span class="dt">good =</span> <span class="kw">sum</span>(!<span class="kw">is.na</span>(x)), <span class="dt">bad =</span> <span class="kw">sum</span>(<span class="kw">is.na</span>(x)))})))
<span class="kw">print</span>(alt.statsNA, <span class="dt">quote=</span><span class="ot">FALSE</span>, <span class="dt">print.gap=</span><span class="dv">5</span>)
<span class="co">#                               good       bad</span>
<span class="co"># classe                       19216         0</span>
<span class="co"># total_accel_belt             19216         0</span>
<span class="co"># var_accel_belt                   0     19216</span>
<span class="co"># roll_belt                    19216         0</span>
<span class="co"># avg_roll_belt                    0     19216</span>
<span class="co"># stddev_roll_belt                 0     19216</span>
<span class="co"># var_roll_belt                    0     19216</span>
<span class="co"># kurtosis_roll_belt               0     19216</span>
<span class="co"># skewness_roll_belt               0     19216</span>
<span class="co"># min_roll_belt                    0     19216</span>
<span class="co"># max_roll_belt                    0     19216</span>
<span class="co"># amplitude_roll_belt              0     19216</span>
<span class="co"># pitch_belt                   19216         0</span>
<span class="co"># avg_pitch_belt                   0     19216</span>
<span class="co"># stddev_pitch_belt                0     19216</span>
<span class="co"># var_pitch_belt                   0     19216</span>
<span class="co"># kurtosis_pitch_belt              0     19216</span>
<span class="co"># skewness_pitch_belt              0     19216</span>
<span class="co"># min_pitch_belt                   0     19216</span>
<span class="co"># max_pitch_belt                   0     19216</span>
<span class="co"># amplitude_pitch_belt             0     19216</span>
<span class="co"># yaw_belt                     19216         0</span>
<span class="co"># avg_yaw_belt                     0     19216</span>
<span class="co"># stddev_yaw_belt                  0     19216</span>
<span class="co"># var_yaw_belt                     0     19216</span>
<span class="co"># kurtosis_yaw_belt                0     19216</span>
<span class="co"># skewness_yaw_belt                0     19216</span>
<span class="co"># min_yaw_belt                     0     19216</span>
<span class="co"># max_yaw_belt                     0     19216</span>
<span class="co"># amplitude_yaw_belt               0     19216</span>
<span class="co"># gyros_belt_x                 19216         0</span>
<span class="co"># gyros_belt_y                 19216         0</span>
<span class="co"># gyros_belt_z                 19216         0</span>
<span class="co"># accel_belt_x                 19216         0</span>
<span class="co"># accel_belt_y                 19216         0</span>
<span class="co"># accel_belt_z                 19216         0</span>
<span class="co"># magnet_belt_x                19216         0</span>
<span class="co"># magnet_belt_y                19216         0</span>
<span class="co"># magnet_belt_z                19216         0</span>
<span class="co"># total_accel_arm              19216         0</span>
<span class="co"># var_accel_arm                    0     19216</span>
<span class="co"># roll_arm                     19216         0</span>
<span class="co"># avg_roll_arm                     0     19216</span>
<span class="co"># stddev_roll_arm                  0     19216</span>
<span class="co"># var_roll_arm                     0     19216</span>
<span class="co"># kurtosis_roll_arm                0     19216</span>
<span class="co"># skewness_roll_arm                0     19216</span>
<span class="co"># min_roll_arm                     0     19216</span>
<span class="co"># max_roll_arm                     0     19216</span>
<span class="co"># amplitude_roll_arm               0     19216</span>
<span class="co"># pitch_arm                    19216         0</span>
<span class="co"># avg_pitch_arm                    0     19216</span>
<span class="co"># stddev_pitch_arm                 0     19216</span>
<span class="co"># var_pitch_arm                    0     19216</span>
<span class="co"># kurtosis_pitch_arm               0     19216</span>
<span class="co"># skewness_pitch_arm               0     19216</span>
<span class="co"># min_pitch_arm                    0     19216</span>
<span class="co"># max_pitch_arm                    0     19216</span>
<span class="co"># amplitude_pitch_arm              0     19216</span>
<span class="co"># yaw_arm                      19216         0</span>
<span class="co"># avg_yaw_arm                      0     19216</span>
<span class="co"># stddev_yaw_arm                   0     19216</span>
<span class="co"># var_yaw_arm                      0     19216</span>
<span class="co"># kurtosis_yaw_arm                 0     19216</span>
<span class="co"># skewness_yaw_arm                 0     19216</span>
<span class="co"># min_yaw_arm                      0     19216</span>
<span class="co"># max_yaw_arm                      0     19216</span>
<span class="co"># amplitude_yaw_arm                0     19216</span>
<span class="co"># gyros_arm_x                  19216         0</span>
<span class="co"># gyros_arm_y                  19216         0</span>
<span class="co"># gyros_arm_z                  19216         0</span>
<span class="co"># accel_arm_x                  19216         0</span>
<span class="co"># accel_arm_y                  19216         0</span>
<span class="co"># accel_arm_z                  19216         0</span>
<span class="co"># magnet_arm_x                 19216         0</span>
<span class="co"># magnet_arm_y                 19216         0</span>
<span class="co"># magnet_arm_z                 19216         0</span>
<span class="co"># total_accel_forearm          19216         0</span>
<span class="co"># var_accel_forearm                0     19216</span>
<span class="co"># roll_forearm                 19216         0</span>
<span class="co"># avg_roll_forearm                 0     19216</span>
<span class="co"># stddev_roll_forearm              0     19216</span>
<span class="co"># var_roll_forearm                 0     19216</span>
<span class="co"># kurtosis_roll_forearm            0     19216</span>
<span class="co"># skewness_roll_forearm            0     19216</span>
<span class="co"># min_roll_forearm                 0     19216</span>
<span class="co"># max_roll_forearm                 0     19216</span>
<span class="co"># amplitude_roll_forearm           0     19216</span>
<span class="co"># pitch_forearm                19216         0</span>
<span class="co"># avg_pitch_forearm                0     19216</span>
<span class="co"># stddev_pitch_forearm             0     19216</span>
<span class="co"># var_pitch_forearm                0     19216</span>
<span class="co"># kurtosis_pitch_forearm           0     19216</span>
<span class="co"># skewness_pitch_forearm           0     19216</span>
<span class="co"># min_pitch_forearm                0     19216</span>
<span class="co"># max_pitch_forearm                0     19216</span>
<span class="co"># amplitude_pitch_forearm          0     19216</span>
<span class="co"># yaw_forearm                  19216         0</span>
<span class="co"># avg_yaw_forearm                  0     19216</span>
<span class="co"># stddev_yaw_forearm               0     19216</span>
<span class="co"># var_yaw_forearm                  0     19216</span>
<span class="co"># kurtosis_yaw_forearm             0     19216</span>
<span class="co"># skewness_yaw_forearm             0     19216</span>
<span class="co"># min_yaw_forearm                  0     19216</span>
<span class="co"># max_yaw_forearm                  0     19216</span>
<span class="co"># amplitude_yaw_forearm            0     19216</span>
<span class="co"># gyros_forearm_x              19216         0</span>
<span class="co"># gyros_forearm_y              19216         0</span>
<span class="co"># gyros_forearm_z              19216         0</span>
<span class="co"># accel_forearm_x              19216         0</span>
<span class="co"># accel_forearm_y              19216         0</span>
<span class="co"># accel_forearm_z              19216         0</span>
<span class="co"># magnet_forearm_x             19216         0</span>
<span class="co"># magnet_forearm_y             19216         0</span>
<span class="co"># magnet_forearm_z             19216         0</span>
<span class="co"># total_accel_dumbbell         19216         0</span>
<span class="co"># var_accel_dumbbell               0     19216</span>
<span class="co"># roll_dumbbell                19216         0</span>
<span class="co"># avg_roll_dumbbell                0     19216</span>
<span class="co"># stddev_roll_dumbbell             0     19216</span>
<span class="co"># var_roll_dumbbell                0     19216</span>
<span class="co"># kurtosis_roll_dumbbell           0     19216</span>
<span class="co"># skewness_roll_dumbbell           0     19216</span>
<span class="co"># min_roll_dumbbell                0     19216</span>
<span class="co"># max_roll_dumbbell                0     19216</span>
<span class="co"># amplitude_roll_dumbbell          0     19216</span>
<span class="co"># pitch_dumbbell               19216         0</span>
<span class="co"># avg_pitch_dumbbell               0     19216</span>
<span class="co"># stddev_pitch_dumbbell            0     19216</span>
<span class="co"># var_pitch_dumbbell               0     19216</span>
<span class="co"># kurtosis_pitch_dumbbell          0     19216</span>
<span class="co"># skewness_pitch_dumbbell          0     19216</span>
<span class="co"># min_pitch_dumbbell               0     19216</span>
<span class="co"># max_pitch_dumbbell               0     19216</span>
<span class="co"># amplitude_pitch_dumbbell         0     19216</span>
<span class="co"># yaw_dumbbell                 19216         0</span>
<span class="co"># avg_yaw_dumbbell                 0     19216</span>
<span class="co"># stddev_yaw_dumbbell              0     19216</span>
<span class="co"># var_yaw_dumbbell                 0     19216</span>
<span class="co"># kurtosis_yaw_dumbbell            0     19216</span>
<span class="co"># skewness_yaw_dumbbell            0     19216</span>
<span class="co"># min_yaw_dumbbell                 0     19216</span>
<span class="co"># max_yaw_dumbbell                 0     19216</span>
<span class="co"># amplitude_yaw_dumbbell           0     19216</span>
<span class="co"># gyros_dumbbell_x             19216         0</span>
<span class="co"># gyros_dumbbell_y             19216         0</span>
<span class="co"># gyros_dumbbell_z             19216         0</span>
<span class="co"># accel_dumbbell_x             19216         0</span>
<span class="co"># accel_dumbbell_y             19216         0</span>
<span class="co"># accel_dumbbell_z             19216         0</span>
<span class="co"># magnet_dumbbell_x            19216         0</span>
<span class="co"># magnet_dumbbell_y            19216         0</span>
<span class="co"># magnet_dumbbell_z            19216         0</span></code></pre>
</div>
<div id="checking-for-zerolow-variance-predictors." class="section level3">
<h3>Checking for zero/low variance predictors.</h3>
<pre class="sourceCode r"><code class="sourceCode r">nzv &lt;-<span class="st"> </span><span class="kw">nearZeroVar</span>(alt.full.select, <span class="dt">saveMetrics=</span><span class="ot">TRUE</span>)
nzv
<span class="co">#                      freqRatio percentUnique zeroVar   nzv</span>
<span class="co"># classe                1.471490    0.02601998   FALSE FALSE</span>
<span class="co"># total_accel_belt      1.069434    0.15091590   FALSE FALSE</span>
<span class="co"># roll_belt             1.086168    6.83805162   FALSE FALSE</span>
<span class="co"># pitch_belt            1.036649    9.53892590   FALSE FALSE</span>
<span class="co"># yaw_belt              1.047244   10.10616153   FALSE FALSE</span>
<span class="co"># gyros_belt_x          1.050784    0.72335554   FALSE FALSE</span>
<span class="co"># gyros_belt_y          1.148947    0.35907577   FALSE FALSE</span>
<span class="co"># gyros_belt_z          1.071098    0.87947544   FALSE FALSE</span>
<span class="co"># accel_belt_x          1.059367    0.85345545   FALSE FALSE</span>
<span class="co"># accel_belt_y          1.115333    0.74417152   FALSE FALSE</span>
<span class="co"># accel_belt_z          1.080702    1.55599500   FALSE FALSE</span>
<span class="co"># magnet_belt_x         1.089080    1.70170691   FALSE FALSE</span>
<span class="co"># magnet_belt_y         1.096519    1.55079101   FALSE FALSE</span>
<span class="co"># magnet_belt_z         1.019481    2.37302248   FALSE FALSE</span>
<span class="co"># total_accel_arm       1.020316    0.34346378   FALSE FALSE</span>
<span class="co"># roll_arm             51.153846   13.75936719   FALSE FALSE</span>
<span class="co"># pitch_arm            85.282051   15.96065779   FALSE FALSE</span>
<span class="co"># yaw_arm              32.281553   14.89904246   FALSE FALSE</span>
<span class="co"># gyros_arm_x           1.023715    3.34616986   FALSE FALSE</span>
<span class="co"># gyros_arm_y           1.450593    1.95149875   FALSE FALSE</span>
<span class="co"># gyros_arm_z           1.118908    1.29059117   FALSE FALSE</span>
<span class="co"># accel_arm_x           1.017751    4.04350541   FALSE FALSE</span>
<span class="co"># accel_arm_y           1.169082    2.78413822   FALSE FALSE</span>
<span class="co"># accel_arm_z           1.139344    4.12156536   FALSE FALSE</span>
<span class="co"># magnet_arm_x          1.011765    6.96294754   FALSE FALSE</span>
<span class="co"># magnet_arm_y          1.045455    4.53268110   FALSE FALSE</span>
<span class="co"># magnet_arm_z          1.027778    6.57785179   FALSE FALSE</span>
<span class="co"># total_accel_forearm   1.132729    0.36427977   FALSE FALSE</span>
<span class="co"># roll_forearm         11.726154   11.23542881   FALSE FALSE</span>
<span class="co"># pitch_forearm        64.576271   15.09679434   FALSE FALSE</span>
<span class="co"># yaw_forearm          15.236000   10.29870941   FALSE FALSE</span>
<span class="co"># gyros_forearm_x       1.050193    1.54558701   FALSE FALSE</span>
<span class="co"># gyros_forearm_y       1.043011    3.84054954   FALSE FALSE</span>
<span class="co"># gyros_forearm_z       1.112051    1.58201499   FALSE FALSE</span>
<span class="co"># accel_forearm_x       1.142857    4.13197336   FALSE FALSE</span>
<span class="co"># accel_forearm_y       1.050000    5.20920067   FALSE FALSE</span>
<span class="co"># accel_forearm_z       1.019231    3.01311407   FALSE FALSE</span>
<span class="co"># magnet_forearm_x      1.012658    7.92568693   FALSE FALSE</span>
<span class="co"># magnet_forearm_y      1.256410    9.72626978   FALSE FALSE</span>
<span class="co"># magnet_forearm_z      1.017544    8.75832639   FALSE FALSE</span>
<span class="co"># total_accel_dumbbell  1.081020    0.22377186   FALSE FALSE</span>
<span class="co"># roll_dumbbell         1.037879   84.17464613   FALSE FALSE</span>
<span class="co"># pitch_dumbbell        2.248175   81.73397169   FALSE FALSE</span>
<span class="co"># yaw_dumbbell          1.132231   83.34721066   FALSE FALSE</span>
<span class="co"># gyros_dumbbell_x      1.010050    1.25416320   FALSE FALSE</span>
<span class="co"># gyros_dumbbell_y      1.270979    1.44150708   FALSE FALSE</span>
<span class="co"># gyros_dumbbell_z      1.052632    1.06681932   FALSE FALSE</span>
<span class="co"># accel_dumbbell_x      1.006061    2.21169858   FALSE FALSE</span>
<span class="co"># accel_dumbbell_y      1.062500    2.41985845   FALSE FALSE</span>
<span class="co"># accel_dumbbell_z      1.150215    2.12323064   FALSE FALSE</span>
<span class="co"># magnet_dumbbell_x     1.093567    5.84929226   FALSE FALSE</span>
<span class="co"># magnet_dumbbell_y     1.188571    4.38176520   FALSE FALSE</span>
<span class="co"># magnet_dumbbell_z     1.026596    3.51269775   FALSE FALSE</span></code></pre>
</div>
<div id="some-handy-functions" class="section level3">
<h3>Some handy functions</h3>
<p>Additional locally defined functions, sourced from the external file.</p>
<pre class="sourceCode r"><code class="sourceCode r">tidy_df &lt;-<span class="st"> </span>function( data ) {
    for(i in <span class="dv">8</span>:<span class="dv">159</span>) { 
        data[,i] &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(data[,i])
    }
    <span class="kw">colnames</span>(data) &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_picth&quot;</span>, <span class="st">&quot;_pitch&quot;</span>, <span class="kw">colnames</span>(data), <span class="dt">perl=</span><span class="ot">TRUE</span>)
    <span class="kw">colnames</span>(data) &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;var_total_accel_&quot;</span>, <span class="st">&quot;var_accel_&quot;</span>, <span class="kw">colnames</span>(data), <span class="dt">perl=</span><span class="ot">TRUE</span>)
    <span class="kw">colnames</span>(data) &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;roll_belt.1&quot;</span>, <span class="st">&quot;pitch_belt&quot;</span>, <span class="kw">colnames</span>(data), <span class="dt">perl=</span><span class="ot">TRUE</span>)
    <span class="kw">return</span>(data)
}

add_new_variables &lt;-<span class="st"> </span>function( data ) { 
    data$classe &lt;-<span class="st"> </span><span class="kw">as.factor</span>(data$classe)
    data$timestamp &lt;-<span class="st"> </span>data$raw_timestamp_part_1 +<span class="st"> </span>data$raw_timestamp_part_2
    data$date &lt;-<span class="st"> </span><span class="kw">strptime</span>(<span class="kw">as.character</span>(data$cvtd_timestamp), <span class="st">&quot;%d/%m/%Y %H:%M&quot;</span>)
    <span class="kw">return</span>(data)
}

select_proper_vars &lt;-<span class="st"> </span>function( data ) {
    vec0 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;total_accel&quot;</span>, <span class="st">&quot;var_accel&quot;</span>)
    
    nn1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;avg&quot;</span>, <span class="st">&quot;stddev&quot;</span>, <span class="st">&quot;var&quot;</span>, <span class="st">&quot;kurtosis&quot;</span>, <span class="st">&quot;skewness&quot;</span>, <span class="st">&quot;min&quot;</span>, <span class="st">&quot;max&quot;</span>, <span class="st">&quot;amplitude&quot;</span>)
    vec1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;roll&quot;</span>, <span class="kw">paste</span>(nn1, <span class="st">&quot;roll&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>), 
              <span class="st">&quot;pitch&quot;</span>, <span class="kw">paste</span>(nn1, <span class="st">&quot;pitch&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>), 
              <span class="st">&quot;yaw&quot;</span>, <span class="kw">paste</span>(nn1, <span class="st">&quot;yaw&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>))
    
    nn2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;gyros&quot;</span>, <span class="st">&quot;accel&quot;</span>, <span class="st">&quot;magnet&quot;</span>)
    vec2 &lt;-<span class="st"> </span><span class="kw">paste</span>( <span class="kw">rep</span>(nn2, <span class="dt">each=</span><span class="dv">3</span>), <span class="st">&quot;VVV&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;x&quot;</span>,<span class="st">&quot;y&quot;</span>,<span class="st">&quot;z&quot;</span>), <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>)
    
    vec.VVV &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">paste</span>(<span class="kw">c</span>(<span class="st">&quot;total_accel&quot;</span>, <span class="st">&quot;var_accel&quot;</span>, vec1), <span class="st">&quot;VVV&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>), vec2)
    vec.belt &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_belt&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    vec.arm &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_arm&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    vec.forearm &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_forearm&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    vec.dumbbell &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_dumbbell&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    i.classe &lt;-<span class="st"> </span><span class="kw">which</span>( <span class="kw">colnames</span>(data) ==<span class="st"> &quot;classe&quot;</span>)
    
    if( <span class="kw">length</span>(i.classe) &gt;<span class="st"> </span><span class="dv">0</span> ) {
        select &lt;-<span class="st"> </span>data[, <span class="kw">c</span>(<span class="st">&quot;classe&quot;</span>, vec.belt, vec.arm, vec.forearm, vec.dumbbell)]
    } else {
        select &lt;-<span class="st"> </span>data[, <span class="kw">c</span>(<span class="st">&quot;problem_id&quot;</span>, vec.belt, vec.arm, vec.forearm, vec.dumbbell)]
    }
    <span class="kw">return</span>(select)
}

<span class="co"># define color palettes</span>
color1 &lt;-<span class="st"> </span><span class="kw">colorRampPalette</span>(<span class="kw">c</span>(<span class="st">&quot;#7F0000&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;#FF7F00&quot;</span>, <span class="st">&quot;yellow&quot;</span>, <span class="st">&quot;white&quot;</span>, 
                             <span class="st">&quot;cyan&quot;</span>, <span class="st">&quot;#007FFF&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;#00007F&quot;</span>))

color2 &lt;-<span class="st"> </span><span class="kw">colorRampPalette</span>(<span class="kw">c</span>(<span class="st">&quot;#67001F&quot;</span>, <span class="st">&quot;#B2182B&quot;</span>, <span class="st">&quot;#D6604D&quot;</span>, <span class="st">&quot;#F4A582&quot;</span>, <span class="st">&quot;#FDDBC7&quot;</span>,
                           <span class="st">&quot;#FFFFFF&quot;</span>, <span class="st">&quot;#D1E5F0&quot;</span>, <span class="st">&quot;#92C5DE&quot;</span>, <span class="st">&quot;#4393C3&quot;</span>, <span class="st">&quot;#2166AC&quot;</span>, <span class="st">&quot;#053061&quot;</span>))   

color3 &lt;-<span class="st"> </span><span class="kw">colorRampPalette</span>(<span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;white&quot;</span>, <span class="st">&quot;blue&quot;</span>))   

<span class="co"># correct answers</span>
answers &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;D&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, 
             <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;B&quot;</span>)</code></pre>
<hr class="thin_separator">
<p><a name="SessionInfo"></a></p>
</div>
<div id="r-session-info" class="section level2">
<h2>R Session Info</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()
<span class="co"># R version 3.1.3 (2015-03-09)</span>
<span class="co"># Platform: x86_64-pc-linux-gnu (64-bit)</span>
<span class="co"># Running under: Ubuntu 14.04.2 LTS</span>
<span class="co"># </span>
<span class="co"># locale:</span>
<span class="co">#  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       </span>
<span class="co">#  [4] LC_COLLATE=C               LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   </span>
<span class="co">#  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              </span>
<span class="co"># [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       </span>
<span class="co"># </span>
<span class="co"># attached base packages:</span>
<span class="co">#  [1] parallel  splines   grid      stats     graphics  grDevices utils     datasets  methods  </span>
<span class="co"># [10] base     </span>
<span class="co"># </span>
<span class="co"># other attached packages:</span>
<span class="co">#  [1] pROC_1.8            rpart_4.1-9         gbm_2.1.1           survival_2.38-1    </span>
<span class="co">#  [5] partykit_1.0-1      randomForest_4.6-10 caret_6.0-47        lattice_0.20-31    </span>
<span class="co">#  [9] rattle_3.4.1        corrplot_0.73       gridExtra_0.9.1     gtable_0.1.2       </span>
<span class="co"># [13] ggplot2_1.0.1       plyr_1.8.3          knitr_1.10.5       </span>
<span class="co"># </span>
<span class="co"># loaded via a namespace (and not attached):</span>
<span class="co">#  [1] BradleyTerry2_1.0-6 MASS_7.3-41         Matrix_1.2-0        Rcpp_0.11.6        </span>
<span class="co">#  [5] SparseM_1.6         brglm_0.5-9         car_2.0-25          class_7.3-12       </span>
<span class="co">#  [9] codetools_0.2-11    colorspace_1.2-6    digest_0.6.8        e1071_1.6-4        </span>
<span class="co"># [13] evaluate_0.7        foreach_1.4.2       formatR_1.2         gtools_3.4.2       </span>
<span class="co"># [17] htmltools_0.2.6     iterators_1.0.7     labeling_0.3        lme4_1.1-8         </span>
<span class="co"># [21] magrittr_1.5        mgcv_1.8-6          minqa_1.2.4         munsell_0.4.2      </span>
<span class="co"># [25] nlme_3.1-120        nloptr_1.0.4        nnet_7.3-9          pbkrtest_0.4-2     </span>
<span class="co"># [29] proto_0.3-10        quantreg_5.11       reshape2_1.4.1      rmarkdown_0.7      </span>
<span class="co"># [33] scales_0.2.4        stringi_0.5-5       stringr_1.0.0       tools_3.1.3        </span>
<span class="co"># [37] yaml_2.1.13</span></code></pre>
<hr />
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
